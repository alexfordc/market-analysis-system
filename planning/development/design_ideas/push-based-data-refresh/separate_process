Design idea for push-based auto-refresh:

Assign the job of determining when there is new data (e.g., from a
real-time feed) to a separate process.  This process will keep track of
the GUI clients that need newly-arrived data to be sent to them (so it
will be a network client of each of these GUI clients).  When the process
becomes aware of newly arrived data, if there is a client waiting for that
data, it will send a request to the main server (the current MAS server)
for the data and send that data to all clients that have "registered"
for it.  I'm not sure exactly what will happen when the main server
receives this request since I'm missing information on the implied
architecture for using the data provider's API.  Perhaps the main server
will then query the data provider's system for the new data, or perhaps
the separate process will get the data and put it into (or append it to)
a file for the main server to read (thus caching the data on the local file
system - ignoring for now the issue of how to keep the cache from getting
too large), or perhaps some other solution will be used.

This design avoids major architectural changes to the main server.
The intended result is that, since the complexity of keeping track of
which clients need to have data pushed to them for which tradables for
which time periods will be implemented in the code for this separate
process, the resulting code base will be cleaner and easier to maintain
than if this complexity was added to the main server.

It may be appropriate for this separate process to also handle the
security brokering (checking passwords, ensuring no non-registered
clients get through, etc.) that will need to be done for larger customers.
